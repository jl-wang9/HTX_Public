{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasting of Objects onto X-ray scans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment this out and run others first before running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***User to define Parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max number of times the algo will attempt to place objects on a single background image. To prevent infinite loops\n",
    "MAX_ATTEMPTS = 100\n",
    "\n",
    "# Customisable parameters [min, max]\n",
    "rotation_range = [0, 360]\n",
    "number_objects_per_image = [1, 5]\n",
    "max_magnification = 1.3 \n",
    "bg_removal_threshold = 250\n",
    "\n",
    "# Only put on white space?\n",
    "# Sometimes it may be good to overlay object in non-whitespace region to make training set more robust.\n",
    "white_space_hunter = True\n",
    "\n",
    "# Give a name for object to place.\n",
    "# Type \"multiple\" if there are multiple classes to place. Class name extracted up to \"_\"\n",
    "# So myObject_1.jpg, myObject_2.jpg will be given class \"myObject\"\n",
    "obj_class = \"my_class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJ_DIR = \"/home/your_obj_dir\"\n",
    "BG_DIR = \"/home/your_bg_dir\"\n",
    "\n",
    "OUT_DIR = \"/home/your_output_dir\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual code begins here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from PIL import Image, ImageFilter, ImageDraw, ImageChops, ImageFont\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main Fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_images():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    \"\"\"\n",
    "    # Output Directory\n",
    "    out_dir_full = os.path.join(OUT_DIR, datetime.now().strftime(\"%Y_%m_%d-%H.%M.%S\"))\n",
    "    os.makedirs(out_dir_full)\n",
    "    os.makedirs(os.path.join(out_dir_full, \"images\"))\n",
    "    os.makedirs(os.path.join(out_dir_full, \"annotations\"))\n",
    "    \n",
    "    # Get list of files\n",
    "    obj_files_list = [file for file in os.listdir(OBJ_DIR) \n",
    "         if os.path.isfile(os.path.join(OBJ_DIR, file))]\n",
    "    bg_files_list = [file for file in os.listdir(BG_DIR) \n",
    "         if os.path.isfile(os.path.join(BG_DIR, file))]\n",
    "    \n",
    "    print(f\"Processing {len(bg_files_list)} images...\\n\")\n",
    "    # Iteratively take bgs and start pasting stuff\n",
    "    for im_indx, bg in enumerate(bg_files_list):\n",
    "        \n",
    "        # Counter to count number of attempts spent on this image\n",
    "        attempt_count = 0\n",
    "        obj_count = 0\n",
    "        \n",
    "        # Decide number of objects to put\n",
    "        obj_to_place = np.random.randint(number_objects_per_image[0], number_objects_per_image[1]+1, size=1)[0]\n",
    "        \n",
    "        # Open background image & Get dimensions\n",
    "        image_bg = cv2.imread(os.path.join(BG_DIR, bg))\n",
    "        height_bg, width_bg, _ = image_bg.shape\n",
    "        img_name_noext = os.path.splitext(bg)[0]\n",
    "        \n",
    "        # Creates XML annotations file\n",
    "        xml_annotation = create_xml_backbone(f\"overlay_{img_name_noext}.jpg\", os.path.join(out_dir_full, \"annotations\"), width_bg, height_bg)\n",
    "        \n",
    "        # Keep placing objects until run out of iterations or number to place is reached!\n",
    "        while attempt_count < MAX_ATTEMPTS and obj_count < obj_to_place:\n",
    "            \n",
    "#             print(\"\\nPlacing objects now...\")\n",
    "            fail_flag = True\n",
    "            \n",
    "            \n",
    "            while fail_flag:\n",
    "                \n",
    "                # Choose object & rotate & magnify\n",
    "                chosen_obj = random.choice(obj_files_list)\n",
    "                rotate_angle = np.random.randint(rotation_range[0], rotation_range[1], size=1)[0]\n",
    "                mag_factor_d = np.random.uniform(low=0, high=1, size=1)[0]\n",
    "                \n",
    "                # Open, rotate, and crop object\n",
    "                image_obj_PIL = Image.open(os.path.join(OBJ_DIR, chosen_obj)).convert('RGB')\n",
    "                image_obj_CV = rotate_and_crop(image_obj_PIL, rotate_angle, mag_factor_d)\n",
    "\n",
    "                # Get dimensions of object\n",
    "                height_obj, width_obj, _ = image_obj_CV.shape\n",
    "\n",
    "                # Get coords to place object (x,y)\n",
    "                placement_coords, try_count = determine_random_coords(image_bg, height_obj, width_obj, height_bg, width_bg)\n",
    "\n",
    "                # Update counter\n",
    "                attempt_count += try_count\n",
    "                \n",
    "                # Place 1 object\n",
    "                if placement_coords != None:\n",
    "                    obj_count += 1\n",
    "                    fail_flag=False\n",
    "                    # Place object onto background\n",
    "#                     print(\"One object placed...\")\n",
    "                    \n",
    "                    # Iterate thru pixels in object image, remove white bg\n",
    "                    for x, row in enumerate(image_obj_CV):\n",
    "                        for y, entry in enumerate(row):\n",
    "                            if np.mean(entry)<=bg_removal_threshold:\n",
    "                                image_bg[placement_coords[1]+x, placement_coords[0]+y]=image_obj_CV[x,y]\n",
    "                    \n",
    "                    # Update XML annotation\n",
    "                    xml_annotation = update_bbox_in_XML(xml_annotation, os.path.splitext(chosen_obj)[0], placement_coords,\n",
    "                       width_obj, height_obj)\n",
    "                     \n",
    "                if attempt_count >= MAX_ATTEMPTS:\n",
    "                    break\n",
    "        \n",
    "            \n",
    "        # Save image\n",
    "        cv2.imwrite(os.path.join(out_dir_full, \"images\", f\"overlay_{img_name_noext}.jpg\"), image_bg)\n",
    "        \n",
    "        # Status message\n",
    "        if len(bg_files_list)<30:\n",
    "            print(f\"{obj_count} objects placed onto {bg}. Staged image Saved.\")\n",
    "            if obj_count==0:\n",
    "                print(f\"No objects placed due to inability to find suitable spot within MAX_ATTEMPTS={MAX_ATTEMPTS}\")\n",
    "            print(\"XML Label saved.\")\n",
    "        elif im_indx%10==0 and im_indx!=0:\n",
    "            print(f\"{im_indx}/{len(bg_files_list)} images processed.\")\n",
    "        \n",
    "        # Write and save XML\n",
    "        dom = minidom.parseString(ET.tostring(xml_annotation))\n",
    "        xml_out = dom.toprettyxml(indent='\\t')\n",
    "        with open(os.path.join(out_dir_full, \"annotations\", f\"overlay_{img_name_noext}.xml\"), \"w\") as f:\n",
    "            f.write(xml_out)\n",
    "        \n",
    "    print(\"\\nAll done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate placement coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_random_coords(image_bg, height_obj, width_obj, height_bg, width_bg):\n",
    "    \"\"\"\n",
    "    Generate a random coordinate to place object\n",
    "    Checks that it is against white background!\n",
    "    \n",
    "    Inputs:\n",
    "\n",
    "\n",
    "    Output:\n",
    "        1. Placement_coords (2x1 tuple) OR None if no suitable coords found!\n",
    "           - Random coordinates to place object at (x,y)\n",
    "        2. try_count\n",
    "            - Number of iterations within current run\n",
    "    \"\"\"\n",
    "    # Get coords of background\n",
    "    xmin, ymin = (0,0)\n",
    "    xmax, ymax = (width_bg, height_bg)\n",
    "\n",
    "    # Generate placement coords & compute max coords and checks\n",
    "        # 1. if threat image lies outside container (not allowed)\n",
    "        # 2. that entire placement area is white\n",
    "    pass_flag = False\n",
    "    try_count = 0\n",
    "    \n",
    "    while not pass_flag:\n",
    "        try_count += 1\n",
    "        \n",
    "        # Generate (x,y) coords and max_coords\n",
    "        placement_coords = [np.random.randint(low=xmin, high=xmax, size=1)[0],\n",
    "                            np.random.randint(low=ymin, high=ymax, size=1)[0]]\n",
    "        max_coords = [placement_coords[0] + width_obj, placement_coords[1] + height_obj]        \n",
    "        \n",
    "#         print(max_coords)\n",
    "        \n",
    "        # Check if slice within image\n",
    "        is_within_image = (check_within_box(xmin, ymin, xmax, ymax, placement_coords[0], placement_coords[1])\n",
    "                         and check_within_box(xmin, ymin, xmax, ymax, max_coords[0], max_coords[1]))\n",
    "        \n",
    "#         print(f\"Within img = {is_within_image}\")\n",
    "        \n",
    "        # Check if proposed placement region is white (if required) and within image\n",
    "        if is_within_image:\n",
    "            if white_space_hunter:\n",
    "                image_slice = image_bg[placement_coords[1]:placement_coords[1]+height_obj, \n",
    "                     placement_coords[0]:placement_coords[0]+width_obj]\n",
    "\n",
    "                region_is_white = all_white_pixels(image_slice)\n",
    "    #             print(image_slice)\n",
    "            else:\n",
    "                region_is_white = True\n",
    "            \n",
    "        else:\n",
    "            region_is_white = False\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Check if proposed coords passes the test\n",
    "        pass_flag = (is_within_image and region_is_white) \n",
    "#         pass_flag = (is_within_image or region_is_white)\n",
    "        \n",
    "        # Stop trying if no suitable spot found\n",
    "        if try_count >= 100:\n",
    "            return None, try_count\n",
    "\n",
    "    return placement_coords, try_count  # (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_within_box(xmin, ymin, xmax, ymax, x, y):\n",
    "    \"\"\"\n",
    "    Helper function: Check if coords (x,y) within bounding box\n",
    "    \n",
    "    True if within box\n",
    "    \"\"\"\n",
    "    return (x > xmin and x < xmax and y > ymin and y < ymax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rotate and Magnify Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_and_crop(img_PIL, rotation_deg=0, mag_factor_d=1):\n",
    "    \"\"\"\n",
    "    Rotates image and crops it\n",
    "    \n",
    "    Input:\n",
    "        1. img_PIL: PIL Object\n",
    "    \n",
    "    Output:\n",
    "        1. img_cv: OpenCV Object\n",
    "    \"\"\"\n",
    "    # Magnify\n",
    "    (width, height) = (img_PIL.width, img_PIL.height)\n",
    "    mag_factor = 1 + mag_factor_d * (max_magnification - 1)\n",
    "    img_PIL = img_PIL.resize((int(round(width * mag_factor)), int(round(height * mag_factor))))\n",
    "    \n",
    "    # Rotate\n",
    "    img_PIL = img_PIL.rotate(angle=rotation_deg, expand=1, fillcolor=(255,255,255))\n",
    "\n",
    "    # Crop\n",
    "    img_PIL = trim(img_PIL)\n",
    "    \n",
    "    # Convert to OpenCV object\n",
    "    img_cv = np.array(img_PIL) \n",
    "    img_cv = img_cv[:, :, ::-1].copy()     # Convert RGB to BGR\n",
    "    \n",
    "    return img_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(im):\n",
    "    \"\"\"\n",
    "    Automatically trims away the excess whitespace in a gun image to get a tighter bounding box.\n",
    "\n",
    "    Input:\n",
    "        1. im (PIL Object)\n",
    "            - Background layer of im MUST be set to L=255\n",
    "\n",
    "    Output:\n",
    "        1. im_cropped (PIL Object)\n",
    "           - Cropped image\n",
    "    \"\"\"\n",
    "#     # Iterate thru pixels in object image, remove white bg\n",
    "#     im_np = np.array(im)\n",
    "#     for x, row in enumerate(im_np):\n",
    "#         for y, entry in enumerate(row):\n",
    "#             if np.mean(entry)>=bg_removal_threshold:\n",
    "#                 im_np[x,y]=[255,255,255]\n",
    "#     im=Image.fromarray(im_np)\n",
    "\n",
    "    # Create bg mask of only white colour\n",
    "    bg = Image.new(im.mode, im.size, 255)\n",
    "\n",
    "    # Pixel by pixel comparison of image and background. All pixels with 255 on image should have value 0 in \"diff\"\n",
    "    diff = ImageChops.difference(im, bg)\n",
    "\n",
    "    # adds two images, dividing the result by scale and adding the offset\n",
    "    diff = ImageChops.add(diff, diff, scale=1.0, offset=0)\n",
    "\n",
    "    # Gets non-zero bounding box of image (ie crops image)\n",
    "    bbox = diff.getbbox()\n",
    "\n",
    "    # Crop image according to bounding box\n",
    "    im_cropped = im.crop(bbox)\n",
    "\n",
    "    return im_cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if slice is white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_white_pixels(image):\n",
    "    \"\"\"\n",
    "    Returns True if all white pixels or False if not all white\n",
    "    \"\"\"\n",
    "    white_flag = True\n",
    "    \n",
    "    H, W = image.shape[:2]\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    for pixel in gray:\n",
    "        if np.mean(pixel)<=245:\n",
    "            white_flag = False\n",
    "    \n",
    "    return white_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For handling XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bbox_in_XML(xml_annotation, selected_threat, placement_coords,\n",
    "                       threat_width, threat_height):\n",
    "    \"\"\"\n",
    "    Adds bounding box info \"Object Node\" into XML labels file\n",
    "\n",
    "    Inputs:\n",
    "        1. xml_annotation (XML ElementTree Object)\n",
    "        2. selected_threat (Name without file extension)\n",
    "        3. placement_coords (Tuple in x,y format)\n",
    "        4. threat_width (x)\n",
    "        5. threat_height (y)\n",
    "\n",
    "    Returns:\n",
    "        1.  xml_annotation (XML ElementTree Object)\n",
    "    \"\"\"\n",
    "    myObject = ET.SubElement(xml_annotation, \"object\")\n",
    "\n",
    "    # Get threat class\n",
    "    #### UNCOMMENT THIS FOR CUSTOMISABLE THREAT CLASS, ELSE ALL SET AS \"RIFLE\" ######\n",
    "\n",
    "    #   threat_tree = ET.parse(os.path.join(root, threats_dir, \"annotations\", f\"{selected_threat}.xml\"))\n",
    "    #   threat_class = threat_tree.find(\"object\").find(\"name\").text\n",
    "    \n",
    "    if obj_class == \"multiple\":\n",
    "        object_class = selected_threat.split('_')[0]\n",
    "    else: \n",
    "        object_class = obj_class\n",
    "    \n",
    "    # Object child nodes\n",
    "    ET.SubElement(myObject, \"name\").text = str(object_class)\n",
    "    ET.SubElement(myObject, \"pose\").text = \"Unspecified\"\n",
    "    ET.SubElement(myObject, \"truncated\").text = \"0\"\n",
    "    ET.SubElement(myObject, \"difficult\").text = \"0\"\n",
    "    bndbox = ET.SubElement(myObject, \"bndbox\")\n",
    "\n",
    "    # bndbox child nodes\n",
    "    ET.SubElement(bndbox, \"xmin\").text = str(placement_coords[0])\n",
    "    ET.SubElement(bndbox, \"ymin\").text = str(placement_coords[1])\n",
    "    ET.SubElement(bndbox, \"xmax\").text = str(placement_coords[0] + threat_width)\n",
    "    ET.SubElement(bndbox, \"ymax\").text = str(placement_coords[1] + threat_height)\n",
    "\n",
    "    return xml_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_backbone(curr_filename, save_dir, img_width, img_height):\n",
    "    \"\"\"\n",
    "    PascalVOC Format\n",
    "    Creates backbone of XML label file, populating tree with everything except object bounding box labels\n",
    "\n",
    "    Returns:\n",
    "        1. xml_annotation (ElementTree Object)\n",
    "    \"\"\"\n",
    "    # Main node\n",
    "    xml_annotation = ET.Element(\"annotation\")\n",
    "\n",
    "    # Primary nodes\n",
    "    ET.SubElement(xml_annotation, \"folder\").text = \"images\"\n",
    "    ET.SubElement(xml_annotation, \"filename\").text = str(curr_filename)\n",
    "    ET.SubElement(xml_annotation, \"path\").text = str(save_dir)\n",
    "    source = ET.SubElement(xml_annotation, \"source\")\n",
    "    size = ET.SubElement(xml_annotation, \"size\")\n",
    "    ET.SubElement(xml_annotation, \"segmented\").text = \"0\"\n",
    "\n",
    "    # Source child node\n",
    "    ET.SubElement(source, \"database\").text = \"Unknown\"\n",
    "\n",
    "    # Size child nodes\n",
    "    ET.SubElement(size, \"width\").text = str(img_width)\n",
    "    ET.SubElement(size, \"height\").text = str(img_height)\n",
    "    ET.SubElement(size, \"depth\").text = \"1\"\n",
    "\n",
    "    return xml_annotation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
