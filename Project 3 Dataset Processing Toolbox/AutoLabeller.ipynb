{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-ray Auto Labeller and Crop\n",
    "\n",
    "## Features: \n",
    "#### 1. Takes X-ray scan and:\n",
    "- Automatically generate PascalVOC labels (saved in XML folder)\n",
    "- Crop objects out from main image\n",
    "\n",
    "#### 2. Takes any given PascalVOC label and:\n",
    "- Generate cropped images from the labels provided\n",
    "\n",
    "## Pre-requisites\n",
    "- root folder containing:\n",
    "    - folder of images to process\n",
    "    - output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 1. Cell below will run the labelling + crop process\n",
    "### How to Use: \n",
    "- Set up directories to use under \"FOR USER INPUT\" section\n",
    "- Comment the 2 blocks of code below out first and run all.\n",
    "- Set CROP_IMAGES to True if you want cropped images and labels to be generated, else write False for just labels\n",
    "- Set OBJECT_CLASS to the type of object you are identifying\n",
    "- set CONTOUR_THRESHOLD for boxing. For light coloured backgrounds, use high number. Dark backgrounds use low number. Adjust to find best result\n",
    "- Run block of code below\n",
    "    - Check preview to see if you are satisfied with the sample bounding boxes\n",
    "- **May need to modify some automatically generated boxes manually. Run next block of code to redo the cropping  from modified XML labels if needed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CROP_IMAGES = True\n",
    "OBJECT_CLASS = 'AN'\n",
    "\n",
    "# Threshold for contour finding (0-255)\n",
    "CONTOUR_THRESHOLD = 245\n",
    "\n",
    "_=run_whole_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run this cell to crop with manually modified XML labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # XML Labels Folder **relative to root**\n",
    "# XML_LABELS_FOLDER = \"datasets/annotations/myLabels_2021_07_27-14.12.10_manualedit\"\n",
    "\n",
    "# crop_from_manual_XML()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# **** Directories & Parameters - FOR USER INPUT ****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Coordinates to identify X-ray region in image\n",
    "XMIN, YMIN = (0,0)\n",
    "XMAX, YMAX = (1280, 900)   \n",
    "\n",
    "# Min and Max size of bounding box to record (in px)\n",
    "# Assume images of size 1024px * 1280px\n",
    "MIN_BBOX_SIZE = 30   # Making this too small may cause incorrect boxes to appear (noise)\n",
    "MAX_BBOX_SIZE = 600  # Making this too large may cause the main window to be taken as a label too\n",
    "\n",
    "PRINT_FREQ = 5       # Frequency of status updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify root directory - all directories are specified relative to this!\n",
    "root = 'home/your_root_here'\n",
    "\n",
    "import os\n",
    "os.chdir(root)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input & Output Directories (Relative to ROOT)\n",
    "\n",
    "image_dir = \"ScreenRecord_131353031904_imgs\"                   # Where the UNCROPPED images are stored\n",
    "output_dir = \"ScreenRecord_131353031904_imgs/output\"           # Output directory for annotations and extracted samples (2 folders will be created)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l0Xu8p0b5kH"
   },
   "source": [
    "---\n",
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JLcONawQb334"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "# from PIL import Image, ImageFilter, ImageDraw, ImageChops, ImageFont\n",
    "import cv2\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.dom import minidom\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# No more editing from here on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs entire process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whole_process():\n",
    "    \n",
    "    ### ====== SETUP ====== ###\n",
    "    \n",
    "    # Define full paths\n",
    "    curr_time = generate_unique_name()\n",
    "    image_dir_full = os.path.join(root, image_dir)\n",
    "    output_dir_full = os.path.join(root, output_dir)\n",
    "    annotations_dir_full = os.path.join(output_dir_full, 'annotations', f\"myLabels_{curr_time}\")\n",
    "    cropped_dir_full = os.path.join(output_dir_full, 'cropped_samples', f\"myCropImgs_{curr_time}\")\n",
    "    \n",
    "    # Get full list of input images\n",
    "    input_imgs = [name for name in os.listdir(image_dir_full) if os.path.isfile(os.path.join(image_dir_full, name))]\n",
    "    \n",
    "    # Let user inspect if boxes are ok, else exit. user_inspect_bbox() returns True if user is satisfied with the boxes.\n",
    "    if not user_inspect_bbox(cv2.imread(os.path.join(image_dir_full, input_imgs[np.random.randint(low=0, high=len(input_imgs), size=1)[0]]))):\n",
    "        print(\"\\nAlright. Modify CONTOUR_THRESHOLD and/or other parameters and run this block of code again! \\nTip: Increase 'MIN_BBOX_SIZE' if there are many incorrect small boxes.\")\n",
    "        return 0\n",
    "    \n",
    "    # Create output folders for labels & cropped images\n",
    "    if not os.path.exists(os.path.join(output_dir_full, 'annotations')):\n",
    "        os.makedirs(os.path.join(output_dir_full, 'annotations'))\n",
    "    os.makedirs(annotations_dir_full)\n",
    "        \n",
    "    if CROP_IMAGES:\n",
    "        print(\"\\nGreat! Now generating XML annotations and cropping images for entire dataset...\")\n",
    "        if not os.path.exists(os.path.join(output_dir_full, 'cropped_samples')):\n",
    "            os.makedirs(os.path.join(output_dir_full, 'cropped_samples'))\n",
    "        os.makedirs(cropped_dir_full)\n",
    "    else:\n",
    "        print(\"\\nGreat! Now generating XML annotations for entire dataset...\")\n",
    "    \n",
    "    \n",
    "    ### ====== Proceed to generate labels and crop images for full dataset ====== ###\n",
    "    \n",
    "    # Cycle thru all images in library\n",
    "    for i, img_name in enumerate(input_imgs):\n",
    "        \n",
    "        # Get image name (without file ext)\n",
    "        img_name_no_ext = os.path.splitext(img_name)[0]\n",
    "        \n",
    "        # Open image and get dimensions\n",
    "        curr_img_full_dir = os.path.join(image_dir_full, img_name)\n",
    "        curr_img = cv2.imread(curr_img_full_dir)\n",
    "        img_height, img_width, _ = curr_img.shape\n",
    "        \n",
    "        # Create label XML backbone\n",
    "        xml_annotation = create_xml_backbone(img_name, curr_img_full_dir, img_width, img_height)\n",
    "        \n",
    "        # Get all contours from one image\n",
    "        ctours = get_all_ctours(curr_img)\n",
    "        \n",
    "        # Each contour_entry is a bbox\n",
    "        counter=0\n",
    "        for contour_entry in ctours:\n",
    "            \n",
    "            # Get bounding rectangle\n",
    "            x,y,w,h = cv2.boundingRect(contour_entry)\n",
    "        \n",
    "            # Only record down bboxes that are in X-ray zone and is not to big nor small\n",
    "            if YMIN<=y<=YMAX and XMIN<=x<=XMAX and pass_size_test(w,h):\n",
    "                counter +=1\n",
    "                \n",
    "                # Generate label by editing XML file\n",
    "                xml_annotation = update_bbox_in_XML(xml_annotation, img_name, (x,y), w, h)\n",
    "            \n",
    "                if CROP_IMAGES:\n",
    "                    # Crop image to the current bounding box\n",
    "                    create_one_crop(x,y,w,h, curr_img, img_name_no_ext, cropped_dir_full, counter)\n",
    "\n",
    "        # Save annotation XML\n",
    "        dom = minidom.parseString(ET.tostring(xml_annotation))\n",
    "        xml_out = dom.toprettyxml(indent='\\t')\n",
    "        with open(os.path.join(annotations_dir_full, f\"{img_name_no_ext}.xml\"), \"w\") as f:\n",
    "            f.write(xml_out)\n",
    "        \n",
    "        # Counter\n",
    "        if (i+1)%PRINT_FREQ==0 or i==(len(input_imgs)-1):\n",
    "            print(f\"{i+1}/{len(input_imgs)} processed!\")\n",
    "          \n",
    "    \n",
    "    if CROP_IMAGES:\n",
    "        print(\"\\nSuccess! XML annotations generated and images cropped!\")\n",
    "    else:\n",
    "        print(\"\\nSuccess! XML annotations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Helper Functions - Image Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_ctours(image):\n",
    "    \"\"\"\n",
    "    Function that gets all primary contours of image (i.e., find objects in scan)\n",
    "    \n",
    "    Input:\n",
    "        image (cv2 object)\n",
    "        \n",
    "    Output:\n",
    "        ctours (list): List of contours\n",
    "    \"\"\"\n",
    "    gray =cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _,binary = cv2.threshold(gray,CONTOUR_THRESHOLD,255,cv2.THRESH_BINARY)\n",
    "    ctours,_ = cv2.findContours(binary,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    return ctours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_inspect_bbox(test_img):\n",
    "    \"\"\"\n",
    "    Function that creates prompt for user to determine if current threshold is satisfactory\n",
    "    \n",
    "    Input:\n",
    "        test_img (cv2 object): Random image in directory\n",
    "        \n",
    "    Output:\n",
    "        user_results (bool): True/False\n",
    "    \"\"\"\n",
    "    # Generates image preview with bounding boxes for user.\n",
    "    gray =cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _,binary = cv2.threshold(gray,CONTOUR_THRESHOLD,255,cv2.THRESH_BINARY)\n",
    "    contours,hierarchy = cv2.findContours(binary,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour_entry in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour_entry)\n",
    "        \n",
    "        # Only plot bboxes that are in X-ray zone and is not to big nor small\n",
    "        if YMIN<=y<=YMAX and XMIN<=x<=XMAX and pass_size_test(w,h):\n",
    "            cv2.rectangle(test_img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \n",
    "    test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize = (100,100))\n",
    "    plt.imshow(test_img)\n",
    "    plt.title('Test Output')\n",
    "    plt.show()\n",
    "    \n",
    "    # User to decide if bounding boxes are satisfactory.\n",
    "    while True:\n",
    "        user_input = input(\"Are you satisfied with these bounding boxes? (Y/N): \")\n",
    "\n",
    "        if user_input in ['Y', 'y', 'Y ', 'y ', 'yes']:\n",
    "            return True\n",
    "        elif user_input in ['N', 'n', 'N ', 'n ', 'no']:\n",
    "            return False\n",
    "        else:\n",
    "            print(\"Invalid answer. Try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions - XML Related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xml_backbone(curr_filename, save_dir, img_width, img_height):\n",
    "    \"\"\"\n",
    "    PascalVOC Format\n",
    "    Creates backbone of XML label file, populating tree with everything except object bounding box labels\n",
    "\n",
    "    Returns:\n",
    "        1. xml_annotation (ElementTree Object)\n",
    "    \"\"\"\n",
    "    # Main node\n",
    "    xml_annotation = ET.Element(\"annotation\")\n",
    "\n",
    "    # Primary nodes\n",
    "    ET.SubElement(xml_annotation, \"folder\").text = \"images\"\n",
    "    ET.SubElement(xml_annotation, \"filename\").text = str(curr_filename)\n",
    "    ET.SubElement(xml_annotation, \"path\").text = str(save_dir)\n",
    "    source = ET.SubElement(xml_annotation, \"source\")\n",
    "    size = ET.SubElement(xml_annotation, \"size\")\n",
    "    ET.SubElement(xml_annotation, \"segmented\").text = \"0\"\n",
    "\n",
    "    # Source child node\n",
    "    ET.SubElement(source, \"database\").text = \"Unknown\"\n",
    "\n",
    "    # Size child nodes\n",
    "    ET.SubElement(size, \"width\").text = str(img_width)\n",
    "    ET.SubElement(size, \"height\").text = str(img_height)\n",
    "    ET.SubElement(size, \"depth\").text = \"1\"\n",
    "\n",
    "    return xml_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bbox_in_XML(xml_annotation, selected_threat, placement_coords,\n",
    "                       threat_width, threat_height):\n",
    "    \"\"\"\n",
    "    Adds bounding box info \"Object Node\" into XML labels file\n",
    "\n",
    "    Inputs:\n",
    "        1. xml_annotation (XML ElementTree Object)\n",
    "        2. selected_threat (Name without file extension)\n",
    "        3. placement_coords (Tuple in x,y format)\n",
    "        4. threat_width (x)\n",
    "        5. threat_height (y)\n",
    "\n",
    "    Returns:\n",
    "        1.  xml_annotation (XML ElementTree Object)\n",
    "    \"\"\"\n",
    "    myObject = ET.SubElement(xml_annotation, \"object\")\n",
    "\n",
    "    # Object child nodes\n",
    "    ET.SubElement(myObject, \"name\").text = str(OBJECT_CLASS)\n",
    "    ET.SubElement(myObject, \"pose\").text = \"Unspecified\"\n",
    "    ET.SubElement(myObject, \"truncated\").text = \"0\"\n",
    "    ET.SubElement(myObject, \"difficult\").text = \"0\"\n",
    "    bndbox = ET.SubElement(myObject, \"bndbox\")\n",
    "\n",
    "    # bndbox child nodes\n",
    "    ET.SubElement(bndbox, \"xmin\").text = str(placement_coords[0])\n",
    "    ET.SubElement(bndbox, \"ymin\").text = str(placement_coords[1])\n",
    "    ET.SubElement(bndbox, \"xmax\").text = str(placement_coords[0] + threat_width)\n",
    "    ET.SubElement(bndbox, \"ymax\").text = str(placement_coords[1] + threat_height)\n",
    "\n",
    "    return xml_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check location and size of bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_size_test(w,h):\n",
    "    \"\"\"\n",
    "    Function evaluates if size of bounding box is ok\n",
    "    \n",
    "    Input:\n",
    "        w, h: width and height of proposed box in px\n",
    "    \n",
    "    Output:\n",
    "        pass_test (bool): True/False\n",
    "    \"\"\"\n",
    "    return (MIN_BBOX_SIZE<=w<=MAX_BBOX_SIZE and MIN_BBOX_SIZE<=h<=MAX_BBOX_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions - Cropping Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_crop(x, y, w, h, curr_img, img_name_no_ext, cropped_dir_full, j):\n",
    "    \"\"\"\n",
    "    Takes in bbox coords and image, crops image to the specified dimensions and save it in output.\n",
    "    \n",
    "    Input:\n",
    "        1. x,y,w,h: bbox coords\n",
    "        2. curr_img (cv2 object): Current image to crop from\n",
    "        3. img_name_no_ext (str): Image name, for generating of output filename\n",
    "        4. cropped_dir_full (str): where to save\n",
    "        5. j (int): Current index of bounding box, for generating of output filename\n",
    "        \n",
    "    Returns: Nil\n",
    "    \n",
    "    Output:\n",
    "        1. png file: Saved to output directory.\n",
    "    \"\"\"\n",
    "    # Crop image\n",
    "    crop_img = curr_img[y:y+h, x:x+w]\n",
    "    \n",
    "    # Choose unique filename\n",
    "    filename = f\"{img_name_no_ext}_{j}.png\"\n",
    "    \n",
    "    # Save image\n",
    "    cv2.imwrite(os.path.join(cropped_dir_full, filename), crop_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function - generate date-time unique folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_name():\n",
    "    \"\"\"\n",
    "    Generates unique folder name according to current date and time\n",
    "    \n",
    "    Returns:\n",
    "        1. unique_name (str): current date time\n",
    "    \"\"\"\n",
    "    curr_datetime = datetime.now().strftime(\"%Y_%m_%d-%H.%M.%S\")\n",
    "    \n",
    "    return curr_datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function - Cropping image with manual XML labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_from_manual_XML():\n",
    "    \"\"\"\n",
    "    Given a PascalVOC XML annotation file and the asociated image, this script \n",
    "    automatically crops out the objects enclosed within the bounding boxes and saves\n",
    "    them as standalone images.\n",
    "    \"\"\"\n",
    "    xml_folder_dir = os.path.join(root, XML_LABELS_FOLDER)\n",
    "    xml_folder_name = os.path.basename(os.path.normpath(xml_folder_dir))\n",
    "    crop_images_output_dir = os.path.join(root, output_dir, 'cropped_samples', f'manualBoxes_{xml_folder_name}')\n",
    "    \n",
    "    # Create new crop folder in output\n",
    "    if not os.path.exists(crop_images_output_dir):\n",
    "        os.mkdir(crop_images_output_dir)\n",
    "\n",
    "    # Get full list of XML files\n",
    "    xml_list = [name for name in os.listdir(xml_folder_dir) if os.path.isfile(os.path.join(xml_folder_dir, name))]\n",
    "    \n",
    "    for i, xml_file in enumerate(xml_list):\n",
    "        # Get name of XML file\n",
    "        xml_filename_noext = os.path.splitext(xml_file)[0]\n",
    "        \n",
    "        # Read XML file\n",
    "        tree = ET.parse(os.path.join(xml_folder_dir, xml_file))\n",
    "        my_root = tree.getroot()\n",
    "        \n",
    "        # Open relevant image from main dataset\n",
    "        curr_img = cv2.imread(os.path.join(root, image_dir, f'{xml_filename_noext}.png'))\n",
    "        \n",
    "        # Extract bbox coords\n",
    "        for j, member in enumerate(my_root.findall('object')):\n",
    "            \n",
    "            values = (int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "\n",
    "            # Crop image\n",
    "            crop_img = curr_img[values[1]:values[3], values[0]:values[2]]\n",
    "\n",
    "            # Choose unique filename\n",
    "            filename = f\"{xml_filename_noext}_{j}.png\"\n",
    "\n",
    "            # Save image\n",
    "            cv2.imwrite(os.path.join(crop_images_output_dir, filename), crop_img)\n",
    "            \n",
    "        # Counter\n",
    "        if (i+1)%PRINT_FREQ==0 or i==(len(xml_list)-1):\n",
    "            print(f\"{i+1}/{len(xml_list)} processed!\")\n",
    "            \n",
    "    print(\"Success! Images cropped. See 'cropped_samples' folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
