{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b041dda-9c95-43ca-a247-ff00c41368ac",
   "metadata": {},
   "source": [
    "# Inference of Detectron model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8da2b8-f661-42f5-870b-07d3b0a37894",
   "metadata": {},
   "source": [
    "## Run All via cell below\n",
    "Comment out cell below 1st!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ef171e-605d-48d0-8235-45b4502e381d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on LABELLED dataset on cpu\n",
      "1/2 images inferred.\n",
      "2/2 images inferred.\n",
      "Inference complete!\n",
      "\n",
      "Evaluating test statistics...\n",
      "\n",
      "Inference complete. Key Results:\n",
      "Avg Precision (IOU50) = 0.9999999999999999\n",
      "Avg Precision (IOU75) = 0.9999999999999999\n",
      "Avg Recall (IOU50) = 0.85\n",
      "\n",
      "Detailed results are available in 'test_results.txt' log in same folder as inference images\n"
     ]
    }
   ],
   "source": [
    "run_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3500d23a-c135-4b3a-b22f-db0188305a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This csv file can be found in the models folder. Default filename is \"labels_train_val.csv\"\n",
    "trained_csv_file = 'your/training/csv/file/here'\n",
    "\n",
    "# Search for this in the models folder. Typically of a few hundred MBs.\n",
    "trained_model_dir = 'your/trained/model/here'\n",
    "\n",
    "# Test images\n",
    "test_dataset_images_dir = 'your/test/images/here'\n",
    "\n",
    "# Test image PascalVOC annotations (OPTIONAL) - leave as '' if needed\n",
    "test_dataset_annotations_dir = 'your/test/annotations/here'\n",
    "# test_dataset_annotations_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a570bc-d5b1-4063-868a-ea9ae9abe619",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers=0\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981dbf1-402b-4a17-9575-95591959da96",
   "metadata": {},
   "source": [
    "## Do not edit below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "106fafde-d7bc-46d5-b4a8-19fa20dc8a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, glob, sys\n",
    "from datetime import datetime as DT\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "from torch import nn, Tensor\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Import selected model - Faster R-CNN ResNet-50 FPN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "# Import from vision\n",
    "os.chdir(\"vision\")\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d59a59f-5277-4f03-bd5f-3655c3aaf77d",
   "metadata": {},
   "source": [
    "## Check if data is labelled or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a3c7db4-b131-495a-b8c6-a441e3413414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations verified! Your test dataset is labelled. Moving to inference...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(test_dataset_annotations_dir):\n",
    "    print(\"Annotations verified! Your test dataset is labelled. Moving to inference...\\n\")\n",
    "    TEST_DATA_IS_LABELLED = True\n",
    "else:\n",
    "    print(\"No annotations found for your test dataset. Inference will still proceed but ground truth boxes and test statistics will not be available....\\n\")\n",
    "    TEST_DATA_IS_LABELLED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8be8a2f-ed70-4961-9fa0-0a36a136da6f",
   "metadata": {},
   "source": [
    "## Process Train CSV\n",
    "Get info on:\n",
    "- Number of classes\n",
    "- Class mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abda1c02-0dda-4991-b416-bdcd64b2e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV\n",
    "my_trained_labels_df = pd.read_csv(trained_csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d80683-d580-479e-adc5-ea0761ed1ecc",
   "metadata": {},
   "source": [
    "## Read Test XML Labels and convert to CSV for groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf2ca2f-c4ba-436c-993d-465db9618c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert xml to csv\n",
    "\n",
    "def xml_to_csv(path):\n",
    "    xml_list = []\n",
    "    for xml_file in glob.glob(path + '/*.xml'):\n",
    "        tree = ET.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        for member in root.findall('object'):\n",
    "            value = (root.find('filename').text,\n",
    "                     int(root.find('size')[0].text),\n",
    "                     int(root.find('size')[1].text),\n",
    "                     member[0].text,\n",
    "                     int(member[4][0].text),\n",
    "                     int(member[4][1].text),\n",
    "                     int(member[4][2].text),\n",
    "                     int(member[4][3].text)\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    return xml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78e453d1-da6a-4a29-93c4-1f8c91a4dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_DATA_IS_LABELLED:\n",
    "    # Find annotations and convert to CSV\n",
    "    test_annotations_dir = os.path.join(test_dataset_annotations_dir)\n",
    "    test_xml_df = xml_to_csv(test_annotations_dir)\n",
    "\n",
    "    # Save CSV for importing by dataloader\n",
    "    my_test_labels_savefile = os.path.join(test_dataset_annotations_dir, f\"test_labels.csv\")\n",
    "    test_xml_df.to_csv(my_test_labels_savefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcafa646-d829-4f79-a079-f34d9815a86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1afe43c-0ffa-4464-8307-4eec5ab87465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace class labels with numbers\n",
    "\n",
    "# Get list of classes in dataframe, including \"0\" background layer\n",
    "list_of_classes = np.array([0])\n",
    "temp_class_list = np.unique(my_trained_labels_df[\"class\"])\n",
    "\n",
    "# Sort in alphabetical order to ensure consistency.\n",
    "temp_class_list = sorted(temp_class_list)\n",
    "list_of_classes = np.append(list_of_classes, temp_class_list).astype(object)\n",
    "\n",
    "# Get number of classes, including bg class\n",
    "num_classes_inference = len(list_of_classes)\n",
    "\n",
    "# Map class names to numbers (e.g. 0 = background, 1 = flammable etc..)\n",
    "for j in range(len(my_trained_labels_df[\"class\"])):\n",
    "  class_index = np.where(list_of_classes == my_trained_labels_df[\"class\"][j])[0][0]\n",
    "  my_trained_labels_df.at[j,\"class\"] = class_index\n",
    "\n",
    "if TEST_DATA_IS_LABELLED:\n",
    "    for k in range(len(test_xml_df[\"class\"])):\n",
    "      class_index = np.where(list_of_classes == test_xml_df[\"class\"][k])[0][0]\n",
    "      test_xml_df.at[k,\"class\"] = class_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f7ed4-5864-4979-bced-17186e30d9a4",
   "metadata": {},
   "source": [
    "## Inference\n",
    "For labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99443027-f6a1-4ce1-8797-1601f9419ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference():\n",
    "    if TEST_DATA_IS_LABELLED:\n",
    "        infer_labelled_data()\n",
    "    else:\n",
    "        run_inference_unlabelled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3a7f38-cc65-4e70-be6e-9bc353989f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_labelled_data():\n",
    "    \n",
    "    # Load Model for test dataset\n",
    "    inference_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Running inference on LABELLED dataset on {inference_device}\")\n",
    "    \n",
    "    loaded_model = get_model(num_classes_inference)\n",
    "    loaded_model.load_state_dict(torch.load(trained_model_dir, \n",
    "        map_location=torch.device(inference_device)))\n",
    "\n",
    "    # Create test results output folder\n",
    "    test_results_dir = os.path.join(test_dataset_images_dir, \"inference_results_images\")\n",
    "    if not os.path.exists(test_results_dir):\n",
    "        os.mkdir(test_results_dir)\n",
    "        \n",
    "    # Directory is named after time and date    \n",
    "    new_dir_name = DT.now().strftime(\"%Y_%m_%d-%H.%M.%S\")\n",
    "    new_dir = os.path.join(test_results_dir, f\"testResults_{new_dir_name}\")\n",
    "    os.mkdir(new_dir)\n",
    "    \n",
    "    # Draw and save inference result\n",
    "    test_size = len(load_test_data())\n",
    "    for i in range(test_size):\n",
    "        prediction = draw_outputs_seen_data(i, new_dir, loaded_model)\n",
    "        if i%2==0 or (i+1)==test_size:\n",
    "            print(f\"{i+1}/{test_size} images inferred.\")\n",
    "            \n",
    "    # Getting test statistics\n",
    "    print(\"\\nInference complete!\")\n",
    "    \n",
    "    print(\"\\nEvaluating test statistics...\\n\")\n",
    "    \n",
    "    loaded_model.to(inference_device)\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "                load_test_data(), batch_size=2, shuffle=False, \n",
    "                num_workers=num_workers,\n",
    "                collate_fn=utils.collate_fn)\n",
    "    \n",
    "    # Save results to log\n",
    "    original_stdout = sys.stdout # Save a reference to the original standard output\n",
    "\n",
    "    with open(os.path.join(new_dir, '_test_results.txt'), 'w') as f:\n",
    "        sys.stdout = f # Change the standard output to the file we created.\n",
    "        print(\"TEST RESULTS\")\n",
    "        print(f'Model Used: {os.path.basename(os.path.normpath(trained_model_dir))}')\n",
    "        print(\"\\n******************************\\n\")\n",
    "        test_eval = evaluate(loaded_model, data_loader_test, device=inference_device)\n",
    "        \n",
    "        sys.stdout = original_stdout # Reset the standard output to its original value\n",
    "    \n",
    "    \n",
    "    # Display key statistics\n",
    "    test_eval_stats = test_eval.coco_eval['bbox'].__dict__['stats']\n",
    "    \n",
    "    print(f\"Inference complete. Here are some key Results:\")\n",
    "    print(f\"Avg Precision (IOU50) = {test_eval_stats[1]}\")\n",
    "    print(f\"Avg Precision (IOU75) = {test_eval_stats[2]}\")\n",
    "    print(f\"Avg Recall (IOU50) = {test_eval_stats[7]}\")\n",
    "    \n",
    "    print(\"\\nDetailed results are available in '_test_results.txt' log in same folder as inference images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d088bc9c-3635-4dcc-9844-1d19cf4f0e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_outputs_seen_data(idx, new_dir, loaded_model):\n",
    "    \"\"\"\n",
    "    Draws inference results.\n",
    "    \"\"\"\n",
    "    dataset_test = load_test_data()\n",
    "\n",
    "    # Get prediction and scores\n",
    "    img, prediction = get_prediction(idx, loaded_model)\n",
    "\n",
    "\n",
    "    # Retrieve torch.tensor containing box coordinate(s) and convert to np.array\n",
    "    # NOTE: Can have multiple label boxes! GROUND TRUTH BOXES\n",
    "    label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
    "    \n",
    "    # Get image and prepare to print image\n",
    "    image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "\n",
    "    # DRAWING BOUNDING BOXES\n",
    "\n",
    "    # Draw groundtruth (GREEN)\n",
    "    for elem in range(len(label_boxes)):\n",
    "        draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "        (label_boxes[elem][2], label_boxes[elem][3])], \n",
    "        outline =\"green\", width =3)\n",
    "\n",
    "    # Draw predicted bounding box (RED)\n",
    "    for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "        # Coords of predicted bouding box. Replaced .cpu() with .detach() for performance\n",
    "        boxes = prediction[0][\"boxes\"][element].detach().numpy()\n",
    "\n",
    "        # Score = confidence level of prediction \n",
    "        score = np.round(prediction[0][\"scores\"][element].detach().numpy(),\n",
    "                          decimals= 4)\n",
    "\n",
    "        # Retrieve predicted class labels (e.g. \"oxidizer\")\n",
    "        predicted_class = prediction[0][\"labels\"][element].detach().numpy()\n",
    "        predicted_classes_label = list_of_classes[predicted_class]\n",
    "\n",
    "        # Only draw predicted bounding boxes exceeding threshold CONF\n",
    "        if score > threshold:\n",
    "            draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], \n",
    "            outline =\"red\", width =3)\n",
    "            draw.text((boxes[0]+5, boxes[1]-12), text = f\"{predicted_classes_label}, {str(score)}\", fill=\"red\")\n",
    "\n",
    "\n",
    "    # Save image\n",
    "    image.save(os.path.join(new_dir, f\"inference_{idx}.jpg\"))\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39fb9475-56d4-4b7f-ae24-c20e745796c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw image\n",
    "\n",
    "def get_prediction(idx, loaded_model):\n",
    "    dataset_test = load_test_data()\n",
    "\n",
    "    # Underscore \"_\" is used as the 2nd output (target dict) is not important. Only want \"img\"\n",
    "    img, _ = dataset_test[idx]\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    loaded_model.eval()\n",
    "\n",
    "\n",
    "    # Retrieve predicted bounding box (red)\n",
    "    # There are MANY predicted bounding boxes, each with a score\n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model([img])\n",
    "\n",
    "    return img, prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aca5c2-a362-4bea-9496-ad2d507d966d",
   "metadata": {},
   "source": [
    "## Inference\n",
    "For unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a368ae71-094a-4b8a-9cc7-931df4dd824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_unlabelled():\n",
    "    \n",
    "    # Load Model for test dataset\n",
    "    inference_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Running inference on UNLABELLED test dataset on {inference_device}\")\n",
    "    \n",
    "    loaded_model = get_model(num_classes_inference)\n",
    "    loaded_model.load_state_dict(torch.load(trained_model_dir, \n",
    "        map_location=torch.device(inference_device)))\n",
    "\n",
    "    # Create test results output folder\n",
    "    test_results_dir = os.path.join(test_dataset_images_dir, \"inference_results_images\")\n",
    "    if not os.path.exists(test_results_dir):\n",
    "        os.mkdir(test_results_dir)\n",
    "        \n",
    "    # Directory is named after time and date    \n",
    "    new_dir_name = DT.now().strftime(\"%Y_%m_%d-%H.%M.%S\")\n",
    "    new_dir = os.path.join(test_results_dir, f\"testResults_{new_dir_name}\")\n",
    "    os.mkdir(new_dir)\n",
    "    \n",
    "    imgs_to_test = [f for f in os.listdir(test_dataset_images_dir) if os.path.isfile(os.path.join(test_dataset_images_dir, f))]\n",
    "    for idx, filename in enumerate(imgs_to_test):\n",
    "        img_path = os.path.join(test_dataset_images_dir, filename)\n",
    "        draw_outputs_unlabelled_data(img_path, loaded_model, new_dir, idx)\n",
    "        test_size = len(imgs_to_test)\n",
    "        \n",
    "        if idx%2==0 or (idx+1)==test_size:\n",
    "            print(f\"{idx+1}/{test_size} images inferred.\")\n",
    "            \n",
    "    print(f\"\\nInference complete. Results saved in {new_dir}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "338baae8-32df-4254-8349-de24c61c382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to draw image\n",
    "\n",
    "def draw_outputs_unlabelled_data(img_path, loaded_model, new_dir, idx):\n",
    "  \n",
    "\n",
    "  # Convert unseen image into tensor\n",
    "  img = Image.open(img_path).convert(\"RGB\")\n",
    "  transforms = T.ToTensor()\n",
    "  # transforms = augment_image(train=False)\n",
    "  target = None\n",
    "  img, target = transforms(img, target)\n",
    "\n",
    "\n",
    "  # Put the model in evaluation mode\n",
    "  loaded_model.eval()\n",
    "\n",
    "  # Retrieve predicted bounding box (red)\n",
    "  # There are MANY predicted bounding boxes, each with a score\n",
    "  with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "\n",
    "\n",
    "  # Get image and prepare to print image\n",
    "  image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  \n",
    "  # Get predicted scores\n",
    "  predicted_scores = prediction[0][\"scores\"].detach().numpy()\n",
    "\n",
    "\n",
    "  if True:\n",
    "    for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "      # Coords of predicted bouding box. Replaced .cpu() with .detach() for performance\n",
    "      boxes = prediction[0][\"boxes\"][element].detach().numpy()\n",
    "\n",
    "      # Score = confidence level of prediction \n",
    "      score = np.round(prediction[0][\"scores\"][element].detach().numpy(),\n",
    "                        decimals= 4)\n",
    "      \n",
    "      # Retrieve predicted class labels (e.g. \"oxidizer\")\n",
    "      predicted_class = prediction[0][\"labels\"][element].detach().numpy()\n",
    "      predicted_classes_label = list_of_classes[predicted_class]\n",
    "      \n",
    "      # Only draw predicted bounding boxes exceeding threshold CONF\n",
    "      if score > threshold:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], \n",
    "        outline =\"red\", width =3)\n",
    "        draw.text((boxes[0]+5, boxes[1]-12), text = f\"{predicted_classes_label}, {str(score)}\", fill=\"black\")\n",
    "\n",
    "\n",
    "  # Save image\n",
    "  image.save(os.path.join(new_dir, f\"inference_{idx}.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830c5fc-186f-495d-b387-6066ab675a5a",
   "metadata": {},
   "source": [
    "## Dataloader and Model loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bcd7b8f-be89-4eb3-8335-8ca2c7a4259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model with required no. of classes\n",
    "\n",
    "def get_model(num_classes):\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "662ef32e-91e8-4fe9-bc14-c33f81fce693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    dataset_test = MyCustomDataset(root= test_dataset_images_dir, \n",
    "                        data_file= my_test_labels_savefile, \n",
    "                        transforms = augment_image(train=False))\n",
    "    return dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40facd50-5300-4a7e-ab9f-035edcbd5d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(train):\n",
    "    # Create new list of original and transformed images\n",
    "    transforms = []\n",
    "\n",
    "    # converts the PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "\n",
    "    # Augments image only if during training stage; train == True:\n",
    "    if train:\n",
    "      # Randomly augment the training images and ground-truths for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e866d46c-82dc-4b99-b2dc-91c99cf9a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data labels\n",
    "# \"labels\" from previously read pandas df of csv file\n",
    "\n",
    "def parse_one_annot(path_to_data_file, filename):                 \n",
    "    # Handle test data\n",
    "    if path_to_data_file == my_test_labels_savefile:\n",
    "        target_row = test_xml_df[test_xml_df[\"filename\"] == filename]  # Extracts one row matching \"filename\" \n",
    "    # Handle trainig data\n",
    "    else:\n",
    "        target_row = my_trained_labels_df[my_trained_labels_df[\"filename\"] == filename] # Extracts one row matching \"filename\"\n",
    "        \n",
    "    boxes_array = target_row[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values         # Extracts bounding coords from that row\n",
    "    class_type = target_row[[\"class\"]].values\n",
    "\n",
    "    return boxes_array, class_type.astype(str).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e23e18-744c-4088-89c7-f7bc53d05ea3",
   "metadata": {},
   "source": [
    "## Custom Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "003120a2-305e-44e7-ab37-3981bbe970dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCustomDataset(torch.utils.data.Dataset):\n",
    "  # Transforms is for data augmentation, by default None but a transforms helper fn is used (see below)\n",
    "  \n",
    "  def __init__(self, root, data_file, transforms=None):\n",
    "    self.root = root\n",
    "    self.transforms = transforms\n",
    "    self.imgs = sorted(f for f in os.listdir(root) if os.path.isfile(os.path.join(root, f)))      # Navigate to image directory\n",
    "    self.path_to_data_file = data_file\n",
    "\n",
    "\n",
    "  # Get image information, returning required tensor \"target\"\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    # PART 0: GET IMAGE PIL FILE\n",
    "    # load EACH image and its bounding boxes\n",
    "    img_path = os.path.join(self.root, self.imgs[idx])        # Get address of each image\n",
    "    img = Image.open(img_path).convert(\"RGB\")                           # Open image and convert to RGB\n",
    "  \n",
    "    # PART 1: GET COORDS OF BOUNDING BOXES   \n",
    "    box_list, class_type_num = parse_one_annot(self.path_to_data_file,                  # Get bounding box coords for this image\n",
    "    self.imgs[idx])\n",
    "    boxes = torch.as_tensor(box_list, dtype=torch.float32)              # Convert array of coords to tensor\n",
    "\n",
    "    # PART 2: GET CLASS LABELS\n",
    "    # To handle multiple classes\n",
    "    class_type_num = class_type_num.transpose()[0] \n",
    "    labels = torch.as_tensor(class_type_num, dtype=torch.int64)\n",
    "    \n",
    "    # PART 3: GET IMAGE_IDs\n",
    "    image_id = torch.tensor([idx])\n",
    "\n",
    "    # PART 4: COMPUTE AREA\n",
    "    area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "\n",
    "    # PART 5: suppose all instances are not crowd so none will be ignored\n",
    "    num_objs = len(box_list)\n",
    "    iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "    # ASSEMBLE REQUIRED TARGET DICTIONARY\n",
    "    target = {}\n",
    "    target[\"boxes\"] = boxes\n",
    "    target[\"labels\"] = labels\n",
    "    target[\"image_id\"] = image_id\n",
    "    target[\"area\"] = area\n",
    "    target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "\n",
    "    if self.transforms is not None:\n",
    "        img, target = self.transforms(img, target)\n",
    "    return img, target\n",
    "\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.imgs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
